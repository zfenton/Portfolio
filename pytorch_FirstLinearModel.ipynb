{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Linear Regression\n",
    "- Data was generated using Spotify Offical API and is available:\n",
    "https://www.kaggle.com/datasets/yasserh/song-popularity-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "songPopularity = pd.read_csv(\"data/song_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>song_duration_ms</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>audio_mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>audio_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boulevard of Broken Dreams</td>\n",
       "      <td>73</td>\n",
       "      <td>262333</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>-4.095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>167.060</td>\n",
       "      <td>4</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In The End</td>\n",
       "      <td>66</td>\n",
       "      <td>216933</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>-6.407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>105.256</td>\n",
       "      <td>4</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seven Nation Army</td>\n",
       "      <td>76</td>\n",
       "      <td>231733</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>-7.828</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>123.881</td>\n",
       "      <td>4</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By The Way</td>\n",
       "      <td>74</td>\n",
       "      <td>216933</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>-4.938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>122.444</td>\n",
       "      <td>4</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How You Remind Me</td>\n",
       "      <td>56</td>\n",
       "      <td>223826</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>-5.065</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>172.011</td>\n",
       "      <td>4</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bring Me To Life</td>\n",
       "      <td>80</td>\n",
       "      <td>235893</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>-3.169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>189.931</td>\n",
       "      <td>4</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Last Resort</td>\n",
       "      <td>81</td>\n",
       "      <td>199893</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2680</td>\n",
       "      <td>-3.659</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>90.578</td>\n",
       "      <td>4</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Are You Gonna Be My Girl</td>\n",
       "      <td>76</td>\n",
       "      <td>213800</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>-3.435</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>105.046</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mr. Brightside</td>\n",
       "      <td>80</td>\n",
       "      <td>222586</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>-3.660</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>148.112</td>\n",
       "      <td>4</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sex on Fire</td>\n",
       "      <td>81</td>\n",
       "      <td>203346</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>-5.653</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>153.398</td>\n",
       "      <td>4</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    song_name  song_popularity  song_duration_ms  \\\n",
       "0  Boulevard of Broken Dreams               73            262333   \n",
       "1                  In The End               66            216933   \n",
       "2           Seven Nation Army               76            231733   \n",
       "3                  By The Way               74            216933   \n",
       "4           How You Remind Me               56            223826   \n",
       "5            Bring Me To Life               80            235893   \n",
       "6                 Last Resort               81            199893   \n",
       "7    Are You Gonna Be My Girl               76            213800   \n",
       "8              Mr. Brightside               80            222586   \n",
       "9                 Sex on Fire               81            203346   \n",
       "\n",
       "   acousticness  danceability  energy  instrumentalness  key  liveness  \\\n",
       "0      0.005520         0.496   0.682          0.000029    8    0.0589   \n",
       "1      0.010300         0.542   0.853          0.000000    3    0.1080   \n",
       "2      0.008170         0.737   0.463          0.447000    0    0.2550   \n",
       "3      0.026400         0.451   0.970          0.003550    0    0.1020   \n",
       "4      0.000954         0.447   0.766          0.000000   10    0.1130   \n",
       "5      0.008950         0.316   0.945          0.000002    4    0.3960   \n",
       "6      0.000504         0.581   0.887          0.001110    4    0.2680   \n",
       "7      0.001480         0.613   0.953          0.000582    2    0.1520   \n",
       "8      0.001080         0.330   0.936          0.000000    1    0.0926   \n",
       "9      0.001720         0.542   0.905          0.010400    9    0.1360   \n",
       "\n",
       "   loudness  audio_mode  speechiness    tempo  time_signature  audio_valence  \n",
       "0    -4.095           1       0.0294  167.060               4          0.474  \n",
       "1    -6.407           0       0.0498  105.256               4          0.370  \n",
       "2    -7.828           1       0.0792  123.881               4          0.324  \n",
       "3    -4.938           1       0.1070  122.444               4          0.198  \n",
       "4    -5.065           1       0.0313  172.011               4          0.574  \n",
       "5    -3.169           0       0.1240  189.931               4          0.320  \n",
       "6    -3.659           0       0.0624   90.578               4          0.724  \n",
       "7    -3.435           1       0.0855  105.046               4          0.537  \n",
       "8    -3.660           1       0.0917  148.112               4          0.234  \n",
       "9    -5.653           1       0.0540  153.398               4          0.374  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songPopularity.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "features = ['song_duration_ms', \n",
    "            'acousticness', 'danceability', \n",
    "            'energy', 'instrumentalness', \n",
    "            'key', 'liveness', 'loudness', \n",
    "            'audio_mode', 'speechiness', \n",
    "            'tempo', 'time_signature', 'audio_valence']\n",
    "\n",
    "target = 'song_popularity'\n",
    "\n",
    "songPopularityFeatures = songPopularity[features]\n",
    "songPopularityTarget = songPopularity[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize train_test_split from sklearn to split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(songPopularityFeatures, songPopularityTarget, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrames into PyTorch tensors\n",
    "def dataframe_to_tensor(df):\n",
    "    return torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "# Transform DataFrames into PyTorch tensors using the function\n",
    "X_train = dataframe_to_tensor(X_train)\n",
    "X_test = dataframe_to_tensor(X_test)\n",
    "y_train = dataframe_to_tensor(y_train)\n",
    "y_test = dataframe_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0559e+05, 8.1200e-02, 7.5600e-01,  ..., 1.4693e+02, 4.0000e+00,\n",
       "         8.1100e-01],\n",
       "        [1.7540e+05, 3.6300e-02, 3.5100e-01,  ..., 1.9567e+02, 4.0000e+00,\n",
       "         8.8000e-01],\n",
       "        [2.3942e+05, 7.9100e-01, 5.4400e-01,  ..., 1.3455e+02, 4.0000e+00,\n",
       "         2.3600e-01],\n",
       "        ...,\n",
       "        [1.3200e+05, 4.0000e-01, 8.5100e-01,  ..., 8.0064e+01, 4.0000e+00,\n",
       "         5.1200e-01],\n",
       "        [1.7136e+05, 4.2700e-03, 5.9700e-01,  ..., 1.2634e+02, 4.0000e+00,\n",
       "         4.4700e-01],\n",
       "        [1.9224e+05, 1.6800e-01, 7.3400e-01,  ..., 1.0447e+02, 4.0000e+00,\n",
       "         7.9300e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first torch.nn.LinearRegression model\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    '''\n",
    "    Torch Module class.\n",
    "    Initializes weight randomly and gets trained via train method.\n",
    "    '''\n",
    "    def __init__(self, optimizer):\n",
    "        super().__init__()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # Initialize Weights and Bias\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.randn(1, 13, dtype=torch.float),\n",
    "            requires_grad=True)\n",
    "\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.randn(1, 13, dtype=torch.float),\n",
    "            requires_grad=True\n",
    "            )\n",
    "    # Goal is to optimize the weights using the optimizer (backpropagation)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            return (self.weights * x + self.bias).sum(axis=1)\n",
    "    # Create trainModel Method to perform backpropogation\n",
    "    # and weight adjustment for optimization\n",
    "    def trainModel(\n",
    "            self,\n",
    "            epochs: int,\n",
    "            X_train: torch.Tensor,\n",
    "            X_test: torch.Tensor,\n",
    "            y_train: torch.Tensor,\n",
    "            y_test: torch.Tensor,\n",
    "            lr: float\n",
    "            ):\n",
    "        '''\n",
    "        Trains linear model using pytorch.\n",
    "        Evaluates the model against test set for every epoch.\n",
    "        '''\n",
    "        torch.manual_seed(42)\n",
    "        # Create empty loss lists to track values\n",
    "        self.train_loss_values = []\n",
    "        self.test_loss_values = []\n",
    "\n",
    "        loss_fn = nn.L1Loss()\n",
    "\n",
    "        if self.optimizer == 'SGD':\n",
    "            optimizer = torch.optim.SGD(\n",
    "                params=self.parameters(),\n",
    "                lr=lr\n",
    "                )\n",
    "        elif self.optimizer == 'Adam':\n",
    "            optimizer = torch.optim.Adam(\n",
    "                params=self.parameters(),\n",
    "                lr=lr\n",
    "                )\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            y_pred = self(X_train)\n",
    "            loss = loss_fn(y_pred, y_train)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Set the model in evaluation mode\n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                self.evaluate(X_test, y_test, epoch, loss_fn, loss)\n",
    "    def evaluate(self, X_test, y_test, epoch_nb, loss_fn, train_loss):\n",
    "        '''\n",
    "        Evaluates current epoch performance on the test set.\n",
    "        '''\n",
    "        test_pred = self(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test.type(torch.float))\n",
    "        if epoch_nb % 10 == 0:\n",
    "            self.train_loss_values.append(train_loss.detach().numpy())\n",
    "            self.test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch_nb} - MAE Train Loss: {train_loss} - MAE Test Loss: {test_loss} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - MAE Train Loss: 73396.3671875 - MAE Test Loss: 73653.859375 \n",
      "Epoch: 10 - MAE Train Loss: 71215.578125 - MAE Test Loss: 71458.890625 \n",
      "Epoch: 20 - MAE Train Loss: 69034.78125 - MAE Test Loss: 69263.9375 \n",
      "Epoch: 30 - MAE Train Loss: 66854.0 - MAE Test Loss: 67068.9765625 \n",
      "Epoch: 40 - MAE Train Loss: 64673.19921875 - MAE Test Loss: 64874.0078125 \n",
      "Epoch: 50 - MAE Train Loss: 62492.40234375 - MAE Test Loss: 62679.0546875 \n",
      "Epoch: 60 - MAE Train Loss: 60311.6171875 - MAE Test Loss: 60484.08984375 \n",
      "Epoch: 70 - MAE Train Loss: 58130.82421875 - MAE Test Loss: 58289.1328125 \n",
      "Epoch: 80 - MAE Train Loss: 55950.03515625 - MAE Test Loss: 56094.1640625 \n",
      "Epoch: 90 - MAE Train Loss: 53769.234375 - MAE Test Loss: 53899.1875 \n",
      "Epoch: 100 - MAE Train Loss: 51588.40625 - MAE Test Loss: 51704.19921875 \n",
      "Epoch: 110 - MAE Train Loss: 49407.58984375 - MAE Test Loss: 49509.19921875 \n",
      "Epoch: 120 - MAE Train Loss: 47226.75390625 - MAE Test Loss: 47314.203125 \n",
      "Epoch: 130 - MAE Train Loss: 45045.9296875 - MAE Test Loss: 45119.2109375 \n",
      "Epoch: 140 - MAE Train Loss: 42865.109375 - MAE Test Loss: 42924.21484375 \n",
      "Epoch: 150 - MAE Train Loss: 40684.28515625 - MAE Test Loss: 40729.22265625 \n",
      "Epoch: 160 - MAE Train Loss: 38503.45703125 - MAE Test Loss: 38534.2265625 \n",
      "Epoch: 170 - MAE Train Loss: 36322.63671875 - MAE Test Loss: 36339.23046875 \n",
      "Epoch: 180 - MAE Train Loss: 34141.80859375 - MAE Test Loss: 34144.23828125 \n",
      "Epoch: 190 - MAE Train Loss: 31960.982421875 - MAE Test Loss: 31949.248046875 \n",
      "Epoch: 200 - MAE Train Loss: 29780.16015625 - MAE Test Loss: 29754.251953125 \n",
      "Epoch: 210 - MAE Train Loss: 27599.337890625 - MAE Test Loss: 27559.259765625 \n",
      "Epoch: 220 - MAE Train Loss: 25418.51171875 - MAE Test Loss: 25364.26171875 \n",
      "Epoch: 230 - MAE Train Loss: 23237.685546875 - MAE Test Loss: 23169.26953125 \n",
      "Epoch: 240 - MAE Train Loss: 21056.861328125 - MAE Test Loss: 20974.275390625 \n",
      "Epoch: 250 - MAE Train Loss: 18876.037109375 - MAE Test Loss: 18779.28125 \n",
      "Epoch: 260 - MAE Train Loss: 16695.212890625 - MAE Test Loss: 16584.2890625 \n",
      "Epoch: 270 - MAE Train Loss: 14514.3876953125 - MAE Test Loss: 14389.29296875 \n",
      "Epoch: 280 - MAE Train Loss: 12333.568359375 - MAE Test Loss: 12194.3056640625 \n",
      "Epoch: 290 - MAE Train Loss: 10152.7529296875 - MAE Test Loss: 9999.3203125 \n",
      "Epoch: 300 - MAE Train Loss: 7971.935546875 - MAE Test Loss: 7804.33349609375 \n",
      "Epoch: 310 - MAE Train Loss: 5791.11865234375 - MAE Test Loss: 5609.34716796875 \n",
      "Epoch: 320 - MAE Train Loss: 3610.302978515625 - MAE Test Loss: 3414.361328125 \n",
      "Epoch: 330 - MAE Train Loss: 1429.4881591796875 - MAE Test Loss: 1219.37744140625 \n",
      "Epoch: 340 - MAE Train Loss: 506.63116455078125 - MAE Test Loss: 578.348876953125 \n",
      "Epoch: 350 - MAE Train Loss: 189.67037963867188 - MAE Test Loss: 71.74773406982422 \n",
      "Epoch: 360 - MAE Train Loss: 89.96098327636719 - MAE Test Loss: 19.66461944580078 \n",
      "Epoch: 370 - MAE Train Loss: 87.32025909423828 - MAE Test Loss: 101.41139221191406 \n",
      "Epoch: 380 - MAE Train Loss: 33.32649230957031 - MAE Test Loss: 54.16037368774414 \n",
      "Epoch: 390 - MAE Train Loss: 36.05447006225586 - MAE Test Loss: 27.08596420288086 \n",
      "Epoch: 400 - MAE Train Loss: 22.046916961669922 - MAE Test Loss: 25.019350051879883 \n",
      "Epoch: 410 - MAE Train Loss: 19.550939559936523 - MAE Test Loss: 21.00244140625 \n",
      "Epoch: 420 - MAE Train Loss: 19.417003631591797 - MAE Test Loss: 19.772489547729492 \n",
      "Epoch: 430 - MAE Train Loss: 19.384004592895508 - MAE Test Loss: 19.385662078857422 \n",
      "Epoch: 440 - MAE Train Loss: 19.38484001159668 - MAE Test Loss: 19.22153091430664 \n",
      "Epoch: 450 - MAE Train Loss: 19.378124237060547 - MAE Test Loss: 19.19622230529785 \n",
      "Epoch: 460 - MAE Train Loss: 19.373117446899414 - MAE Test Loss: 19.15809440612793 \n",
      "Epoch: 470 - MAE Train Loss: 19.36989974975586 - MAE Test Loss: 19.162473678588867 \n",
      "Epoch: 480 - MAE Train Loss: 19.36682891845703 - MAE Test Loss: 19.152002334594727 \n",
      "Epoch: 490 - MAE Train Loss: 19.36386489868164 - MAE Test Loss: 19.152753829956055 \n"
     ]
    }
   ],
   "source": [
    "# Train model using Adam optimizer and 0.001 learning rate\n",
    "adam_model = LinearRegressionModel('Adam')\n",
    "\n",
    "adam_model.trainModel(500, X_train, X_test, y_train, y_test, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - MAE Train Loss: 73396.3671875 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 10 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 20 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 30 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 40 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 50 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 60 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 70 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 80 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 90 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 100 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 110 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 120 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 130 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 140 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 150 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 160 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 170 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 180 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 190 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 200 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 210 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 220 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 230 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 240 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 250 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 260 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 270 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 280 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 290 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 300 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 310 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 320 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 330 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 340 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 350 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 360 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 370 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 380 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 390 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 400 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 410 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 420 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 430 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 440 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 450 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 460 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 470 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 480 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n",
      "Epoch: 490 - MAE Train Loss: 73396.640625 - MAE Test Loss: 47727616.0 \n"
     ]
    }
   ],
   "source": [
    "# Now use Stochastic Gradient Descent (SGD) optimizer with 0.001 learning rate\n",
    "# Notice that the MAE does not improve. SGD is very sensitive to features and could be optimized by feature scaling\n",
    "sgd_model = LinearRegressionModel('SGD')\n",
    "sgd_model.trainModel(500, X_train, X_test, y_train, y_test, 0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
